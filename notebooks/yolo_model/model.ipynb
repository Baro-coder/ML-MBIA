{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# -- Core\n",
    "import time\n",
    "import datetime\n",
    "import logging\n",
    "\n",
    "# -- TQDM\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -- OpenCV\n",
    "import cv2\n",
    "\n",
    "# -- Numpy\n",
    "import numpy as np\n",
    "\n",
    "# -- Tensorflow and Keras\n",
    "import tensorflow as tf\n",
    "from keras import Model\n",
    "from keras.layers import Add,Concatenate,Conv2D,Input,Lambda,LeakyReLU,MaxPool2D,UpSampling2D,ZeroPadding2D,BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.callbacks import ReduceLROnPlateau,EarlyStopping,ModelCheckpoint,TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Constrainsts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "DATA_DIR = '../../data'\n",
    "\n",
    "# Images info CSV file\n",
    "ALL_DATA_CSV_FILEPATH = f'{DATA_DIR}/all-data.csv'\n",
    "\n",
    "# Cell classes dictionary\n",
    "class_dict = {\n",
    "    'red blood cell':0,\n",
    "    'trophozoite': 1, \n",
    "    'schizont': 2, \n",
    "    'difficult': 3, \n",
    "    'ring': 4,\n",
    "    'leukocyte': 5, \n",
    "    'gametocyte': 6\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initializing variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes count : 7\n"
     ]
    }
   ],
   "source": [
    "# YOLO anchors\n",
    "yolo_anchors = np.array([(10, 13), (16, 30), (33, 23), (30, 61), (62, 45),\n",
    "                         (59, 119), (116, 90), (156, 198), (373, 326)],\n",
    "                        np.float32) / 416\n",
    "# YOLO masks\n",
    "yolo_anchor_masks = np.array([[6, 7, 8], [3, 4, 5], [0, 1, 2]])\n",
    "\n",
    "batch_size = 8          # packets count\n",
    "\n",
    "size = 416              # size of resize image\n",
    "yolo_max_boxes = 223    # maximum yolo boxes predicted per image (if there are less, the others will be filled with zeros)\n",
    "\n",
    "yolo_iou_threshold = 0.5        # IOU threshold score \n",
    "yolo_score_threshold = 0.4      # objectness threshold score\n",
    "learning_rate = 1e-4            # learning rate\n",
    "epochs = 100                    # epochs run to fine tune our model\n",
    "\n",
    "\n",
    "classes_count = len(class_dict.items()) # categories count\n",
    "print(f'Classes count : {classes_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Darknet layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution Layer\n",
    "def DarknetConv(x, filters, size, strides=1, batch_norm=True):\n",
    "    if strides == 1:\n",
    "        padding = 'same'\n",
    "    else:\n",
    "        x = ZeroPadding2D(((1, 0), (1, 0)))(x)  # top left half-padding \n",
    "        padding = 'valid' \n",
    "    x = Conv2D(filters=filters, kernel_size=size,\n",
    "               strides=strides, padding=padding,\n",
    "               use_bias=not batch_norm, kernel_regularizer=l2(0.0005))(x)\n",
    "    if batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(alpha=0.1)(x)\n",
    "    return x\n",
    "\n",
    "# Residual Connection Layer\n",
    "def DarknetResidual(x, filters):\n",
    "    prev = x\n",
    "    x = DarknetConv(x, filters // 2, 1) \n",
    "    x = DarknetConv(x, filters, 3)\n",
    "    x = Add()([prev, x])\n",
    "    return x\n",
    "\n",
    "# Darknetblock function - caller for layers \n",
    "def DarknetBlock(x, filters, blocks):\n",
    "    x = DarknetConv(x, filters, 3, strides=2) \n",
    "    for _ in range(blocks):\n",
    "        x = DarknetResidual(x, filters)\n",
    "    return x\n",
    "\n",
    "# Neural Network - Darknet Architecture\n",
    "def Darknet(name=None):\n",
    "    x = inputs = Input([None, None, 3])\n",
    "    x = DarknetConv(x, 32, 3)\n",
    "    x = DarknetBlock(x, 64, 1)\n",
    "    x = DarknetBlock(x, 128, 2)\n",
    "    x = x_36 = DarknetBlock(x, 256, 8)\n",
    "    x = x_61 = DarknetBlock(x, 512, 8)\n",
    "    x = DarknetBlock(x, 1024, 4)\n",
    "    return Model(inputs, (x_36, x_61, x), name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOLO Convolution Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO Convolution layer\n",
    "def YoloConv(filters, name=None):\n",
    "    def yolo_conv(x_in):\n",
    "        if isinstance(x_in, tuple):\n",
    "            inputs = Input(x_in[0].shape[1:]), Input(x_in[1].shape[1:])\n",
    "            x, x_skip = inputs\n",
    "\n",
    "            x = DarknetConv(x, filters, 1)\n",
    "            x = UpSampling2D(2)(x)\n",
    "            x = Concatenate()([x, x_skip])\n",
    "        else:\n",
    "            x = inputs = Input(x_in.shape[1:])\n",
    "        \n",
    "        x = DarknetConv(x, filters, 1)\n",
    "        x = DarknetConv(x, filters * 2, 3)\n",
    "        x = DarknetConv(x, filters, 1)\n",
    "        x = DarknetConv(x, filters * 2, 3)\n",
    "        x = DarknetConv(x, filters, 1)\n",
    "        return Model(inputs, x, name=name)(x_in)\n",
    "    return yolo_conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOLO:**\n",
    " - Output, \n",
    " - Loss Function\n",
    " - Non-Maximum Suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def YoloOutput(filters, anchors, classes, name=None):\n",
    "    def yolo_output(x_in):\n",
    "        x = inputs = Input(x_in.shape[1:])\n",
    "        x = DarknetConv(x, filters * 2, 3)\n",
    "        \n",
    "        x = DarknetConv(x, anchors * (classes + 5), 1, batch_norm=False)\n",
    "        x = Lambda(lambda x: tf.reshape(x, (-1, tf.shape(x)[1], tf.shape(x)[2],\n",
    "                                            anchors, classes + 5)))(x)\n",
    "\n",
    "        return Model(inputs, x, name=name)(x_in)\n",
    "    return yolo_output\n",
    "\n",
    "\n",
    "def yolo_boxes(pred, anchors, classes):\n",
    "    grid_size = tf.shape(pred)[1]\n",
    "    box_xy, box_wh, objectness, class_probs = tf.split(\n",
    "        pred, (2, 2, 1, classes), axis=-1)\n",
    "\n",
    "    box_xy = tf.sigmoid(box_xy) \n",
    "    objectness = tf.sigmoid(objectness)\n",
    "    class_probs = tf.sigmoid(class_probs)\n",
    "    pred_box = tf.concat((box_xy, box_wh), axis=-1)\n",
    "\n",
    "    grid = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))\n",
    "    grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)\n",
    "\n",
    "    box_xy = (box_xy + tf.cast(grid, tf.float32)) / \\\n",
    "        tf.cast(grid_size, tf.float32)\n",
    "    box_wh = tf.exp(box_wh) * anchors\n",
    "\n",
    "    box_x1y1 = box_xy - box_wh / 2 \n",
    "    box_x2y2 = box_xy + box_wh / 2\n",
    "    bbox = tf.concat([box_x1y1, box_x2y2], axis=-1)\n",
    "\n",
    "    return bbox, objectness, class_probs, pred_box\n",
    "\n",
    "def yolo_nms(outputs, anchors, masks, classes):\n",
    "\n",
    "    b, c, t = [], [], []\n",
    "\n",
    "    # iterating through each outputs predicted by model\n",
    "    for o in outputs:\n",
    "        b.append(tf.reshape(o[0], (tf.shape(o[0])[0], -1, tf.shape(o[0])[-1])))\n",
    "        c.append(tf.reshape(o[1], (tf.shape(o[1])[0], -1, tf.shape(o[1])[-1])))\n",
    "        t.append(tf.reshape(o[2], (tf.shape(o[2])[0], -1, tf.shape(o[2])[-1])))\n",
    "\n",
    "    bbox = tf.concat(b, axis=1)\n",
    "    confidence = tf.concat(c, axis=1)\n",
    "    class_probs = tf.concat(t, axis=1)\n",
    "\n",
    "    scores = confidence * class_probs\n",
    "    \n",
    "    boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\n",
    "        boxes=tf.reshape(bbox, (tf.shape(bbox)[0], -1, 1, 4)),\n",
    "        scores=tf.reshape(\n",
    "            scores, (tf.shape(scores)[0], -1, tf.shape(scores)[-1])),\n",
    "        max_output_size_per_class = yolo_max_boxes,\n",
    "        max_total_size = yolo_max_boxes,\n",
    "        iou_threshold = yolo_iou_threshold,\n",
    "        score_threshold = yolo_score_threshold\n",
    "    )\n",
    "\n",
    "    return boxes, scores, classes, valid_detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOLOv3 Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def YoloV3(size=None, channels=3, anchors=yolo_anchors,\n",
    "           masks=yolo_anchor_masks, classes=80, training=False):\n",
    "    x = inputs = Input([size, size, channels], name='input')\n",
    "\n",
    "    x_36, x_61, x = Darknet(name='yolo_darknet')(x)\n",
    "\n",
    "    x = YoloConv(512, name='yolo_conv_0')(x) \n",
    "    output_0 = YoloOutput(512, len(masks[0]), classes, name='yolo_output_0')(x)\n",
    "    \n",
    "    x = YoloConv(256, name='yolo_conv_1')((x, x_61))\n",
    "    output_1 = YoloOutput(256, len(masks[1]), classes, name='yolo_output_1')(x)\n",
    "\n",
    "    x = YoloConv(128, name='yolo_conv_2')((x, x_36))\n",
    "    output_2 = YoloOutput(128, len(masks[2]), classes, name='yolo_output_2')(x)\n",
    "\n",
    "    if training:\n",
    "        return Model(inputs, (output_0, output_1, output_2), name='yolov3')\n",
    "\n",
    "    boxes_0 = Lambda(lambda x: yolo_boxes(x, anchors[masks[0]], classes),\n",
    "                     name='yolo_boxes_0')(output_0)\n",
    "    boxes_1 = Lambda(lambda x: yolo_boxes(x, anchors[masks[1]], classes),\n",
    "                     name='yolo_boxes_1')(output_1)\n",
    "    boxes_2 = Lambda(lambda x: yolo_boxes(x, anchors[masks[2]], classes),\n",
    "                     name='yolo_boxes_2')(output_2)\n",
    "\n",
    "    outputs = Lambda(lambda x: yolo_nms(x, anchors, masks, classes),\n",
    "                     name='yolo_nms')((boxes_0[:3], boxes_1[:3], boxes_2[:3]))\n",
    "\n",
    "    return Model(inputs, outputs, name='yolov3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOLO Loss Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intersection over Union ratio calculation function\n",
    "def broadcast_iou(box_1, box_2):\n",
    "    box_1 = tf.expand_dims(box_1, -2)\n",
    "    box_2 = tf.expand_dims(box_2, 0)\n",
    "    \n",
    "    new_shape = tf.broadcast_dynamic_shape(tf.shape(box_1), tf.shape(box_2))\n",
    "    box_1 = tf.broadcast_to(box_1, new_shape)\n",
    "    box_2 = tf.broadcast_to(box_2, new_shape)\n",
    "\n",
    "    int_w = tf.maximum(tf.minimum(box_1[..., 2], box_2[..., 2]) -\n",
    "                       tf.maximum(box_1[..., 0], box_2[..., 0]), 0) \n",
    "    int_h = tf.maximum(tf.minimum(box_1[..., 3], box_2[..., 3]) -\n",
    "                       tf.maximum(box_1[..., 1], box_2[..., 1]), 0) \n",
    "    int_area = int_w * int_h \n",
    "    box_1_area = (box_1[..., 2] - box_1[..., 0]) * \\\n",
    "        (box_1[..., 3] - box_1[..., 1])\n",
    "    box_2_area = (box_2[..., 2] - box_2[..., 0]) * \\\n",
    "        (box_2[..., 3] - box_2[..., 1])\n",
    "\n",
    "    # Formula: Union(A,B) = A + B - Inter(A,B)\n",
    "    return int_area / (box_1_area + box_2_area - int_area)\n",
    "\n",
    "\n",
    "# YOLO Loss function \n",
    "def YoloLoss(anchors, classes=80, ignore_thresh=0.5):\n",
    "    def yolo_loss(y_true, y_pred):\n",
    "        # 1. transform all pred outputs\n",
    "        pred_box, pred_obj, pred_class, pred_xywh = yolo_boxes(\n",
    "            y_pred, anchors, classes)\n",
    "        pred_xy = pred_xywh[..., 0:2]\n",
    "        pred_wh = pred_xywh[..., 2:4]\n",
    "\n",
    "        # 2. transform all true outputs\n",
    "        \n",
    "        true_box, true_obj, true_class_idx = tf.split(\n",
    "            y_true, (4, 1, 1), axis=-1) \n",
    "\n",
    "        true_xy = (true_box[..., 0:2] + true_box[..., 2:4]) / 2 # finding center (Xcen,Ycen)\n",
    "        true_wh = true_box[..., 2:4] - true_box[..., 0:2] # width and height\n",
    "\n",
    "        box_loss_scale = 2 - true_wh[..., 0] * true_wh[..., 1]\n",
    "\n",
    "        # 3. inverting the pred box equations\n",
    "        grid_size = tf.shape(y_true)[1]\n",
    "        grid = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))\n",
    "        grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)\n",
    "        true_xy = true_xy * tf.cast(grid_size, tf.float32) - \\\n",
    "            tf.cast(grid, tf.float32)\n",
    "\n",
    "        true_wh = tf.math.log(true_wh / anchors) \n",
    "        true_wh = tf.where(tf.math.is_inf(true_wh),\n",
    "                           tf.zeros_like(true_wh), true_wh)\n",
    "\n",
    "        # 4. calculate all masks\n",
    "        obj_mask = tf.squeeze(true_obj, -1)\n",
    "        \n",
    "        best_iou = tf.map_fn(\n",
    "            lambda x: tf.reduce_max(broadcast_iou(x[0], tf.boolean_mask(\n",
    "                x[1], tf.cast(x[2], tf.bool))), axis=-1),\n",
    "            (pred_box, true_box, obj_mask),\n",
    "            tf.float32)\n",
    "        ignore_mask = tf.cast(best_iou < ignore_thresh, tf.float32)\n",
    "\n",
    "        # 5. calculate all losses\n",
    "        xy_loss = obj_mask * box_loss_scale * \\\n",
    "            tf.reduce_sum(tf.square(true_xy - pred_xy), axis=-1)\n",
    "        wh_loss = obj_mask * box_loss_scale * \\\n",
    "            tf.reduce_sum(tf.square(true_wh - pred_wh), axis=-1)\n",
    "        \n",
    "        obj_loss = binary_crossentropy(true_obj, pred_obj)\n",
    "        \n",
    "        # https://leimao.github.io/blog/Focal-Loss-Explained/\n",
    "        \n",
    "        alpha = 0.85\n",
    "        conf_focal = tf.pow(obj_mask-tf.squeeze(tf.sigmoid(pred_obj),-1),2)\n",
    "        obj_loss = conf_focal*((1-alpha)*obj_mask*obj_loss + alpha*(1-obj_mask)*ignore_mask*obj_loss)\n",
    "\n",
    "        class_loss = obj_mask * binary_crossentropy(\n",
    "            true_class_idx, pred_class)\n",
    "\n",
    "        # 6. sum over (batch, gridx, gridy, anchors) => (batch, 1)\n",
    "        xy_loss = tf.reduce_sum(xy_loss, axis=(1, 2, 3))\n",
    "        wh_loss = tf.reduce_sum(wh_loss, axis=(1, 2, 3))\n",
    "        obj_loss = tf.reduce_sum(obj_loss, axis=(1, 2, 3))\n",
    "        class_loss = tf.reduce_sum(class_loss, axis=(1, 2, 3))\n",
    "\n",
    "        return xy_loss + wh_loss + obj_loss + class_loss\n",
    "    return yolo_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utils**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOLOV3_LAYER_LIST = ['yolo_darknet','yolo_conv_0','yolo_output_0','yolo_conv_1',\n",
    "                     'yolo_output_1','yolo_conv_2','yolo_output_2',]\n",
    "\n",
    "# load saved darkent weights\n",
    "def load_darknet_weights(model, weights_file, tiny=False):\n",
    "    wf = open(weights_file, 'rb')\n",
    "    major, minor, revision, seen, _ = np.fromfile(wf, dtype=np.int32, count=5)\n",
    "\n",
    "    layers = YOLOV3_LAYER_LIST\n",
    "\n",
    "    for layer_name in layers:\n",
    "        sub_model = model.get_layer(layer_name)\n",
    "        for i, layer in enumerate(sub_model.layers):\n",
    "            if not layer.name.startswith('conv2d'): \n",
    "                continue\n",
    "            batch_norm = None\n",
    "            if i + 1 < len(sub_model.layers) and \\\n",
    "                    sub_model.layers[i + 1].name.startswith('batch_norm'):\n",
    "                batch_norm = sub_model.layers[i + 1]\n",
    "\n",
    "            logging.info(\"{}/{} {}\".format(\n",
    "                sub_model.name, layer.name, 'bn' if batch_norm else 'bias'))\n",
    "\n",
    "            filters = layer.filters\n",
    "            size = layer.kernel_size[0]\n",
    "            in_dim = layer.input_shape[-1]\n",
    "\n",
    "            if batch_norm is None:\n",
    "                conv_bias = np.fromfile(wf, dtype=np.float32, count=filters)\n",
    "            else:\n",
    "                bn_weights = np.fromfile(\n",
    "                    wf, dtype=np.float32, count=4 * filters)\n",
    "                bn_weights = bn_weights.reshape((4, filters))[[1, 0, 2, 3]]\n",
    "\n",
    "            conv_shape = (filters, in_dim, size, size)\n",
    "            conv_weights = np.fromfile(\n",
    "                wf, dtype=np.float32, count=np.product(conv_shape))\n",
    "            conv_weights = conv_weights.reshape(\n",
    "                conv_shape).transpose([2, 3, 1, 0])\n",
    "\n",
    "            if batch_norm is None:\n",
    "                layer.set_weights([conv_weights, conv_bias])\n",
    "            else:\n",
    "                layer.set_weights([conv_weights])\n",
    "                batch_norm.set_weights(bn_weights)\n",
    "\n",
    "    assert len(wf.read()) == 0, 'failed to read all data'\n",
    "    wf.close()\n",
    "    \n",
    "\n",
    "# Visualize output\n",
    "def draw_outputs(img, outputs, class_names,no_rbc = True):\n",
    "    boxes, objectness, classes, nums = outputs # predicted outputs\n",
    "    boxes, objectness, classes, nums = boxes[0], objectness[0], classes[0], nums[0]\n",
    "    wh = np.flip(img.shape[0:2])\n",
    "\n",
    "    for i in range(nums):\n",
    "        if no_rbc:\n",
    "            if classes[i]==0:\n",
    "                continue \n",
    "        x1y1 = tuple((np.array(boxes[i][0:2]) * wh).astype(np.int32))\n",
    "        x2y2 = tuple((np.array(boxes[i][2:4]) * wh).astype(np.int32))\n",
    "        img = cv2.rectangle(img, x1y1, x2y2, (255, 0, 0), 2)\n",
    "        img = cv2.putText(img, '{} {:.4f}'.format(\n",
    "            class_names[int(classes[i])], objectness[i]),\n",
    "            x1y1, cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 2)\n",
    "    return img\n",
    "\n",
    "\n",
    "# Freeze all layers in model\n",
    "def freeze_all(model, frozen=True):\n",
    "    model.trainable = not frozen\n",
    "    if isinstance(model, tf.keras.Model):\n",
    "        for l in model.layers:\n",
    "            freeze_all(l, frozen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data loader and transformation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below function parse the created csv file and structured into yolo acceptable format\n",
    "# data : dataframe which was created above\n",
    "# class_dict: dictionary containing classes with index(created above)\n",
    "# size : Input size of each image (here by default is 416)\n",
    "# path : path to images data folder\n",
    "\n",
    "def parse_dataset(data, class_dict, size,image, path, yolo_max_boxes, count=0):\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for img in tqdm(image):\n",
    "        x_train = Image.open(path+img)\n",
    "        width,height = x_train.size\n",
    "        x_train = x_train.resize((size,size))\n",
    "        x_train = np.array(x_train)\n",
    "        temp_data = []\n",
    "\n",
    "        for _,row in data[data['img_path']==path+img].iterrows():\n",
    "            xmin = row.min_c / width\n",
    "            xmax = row.max_c / width\n",
    "            ymin = row.min_r / height\n",
    "            ymax = row.max_r / height\n",
    "            cls = class_dict[row.category]\n",
    "            temp_data.append([xmin,ymin,xmax,ymax,cls])\n",
    "        temp_data = temp_data+[[0,0,0,0,0]]*(yolo_max_boxes-len(temp_data))\n",
    "        #return(temp)\n",
    "        Y.append(temp_data)\n",
    "        X.append(x_train)\n",
    "    return(np.array(X),np.stack(np.array(Y)))\n",
    "\n",
    "\n",
    "def transform_images(x,size):\n",
    "    x = tf.image.resize(x,(size,size))\n",
    "    x = x/255.0\n",
    "    return(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
