{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Init**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modules and Globals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-14 22:09:56.066697: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-14 22:09:56.066792: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-14 22:09:56.112143: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-14 22:09:56.205124: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-14 22:09:57.258493: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "# -- Core\n",
    "import time\n",
    "import datetime\n",
    "import logging\n",
    "\n",
    "# -- OpenCV\n",
    "import cv2\n",
    "\n",
    "# -- Numpy\n",
    "import numpy as np\n",
    "\n",
    "# -- Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# -- TQDM\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -- Tensorflow and Keras\n",
    "import tensorflow as tf\n",
    "from keras import Model\n",
    "from keras.layers import Add, Concatenate, Conv2D, Input, Lambda, LeakyReLU, MaxPool2D, UpSampling2D, ZeroPadding2D, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Globals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "DATA_DIR = '../../data'\n",
    "\n",
    "# Images info CSV file\n",
    "ALL_DATA_CSV_FILEPATH = f'{DATA_DIR}/all-data.csv'\n",
    "\n",
    "# Cell classes dictionary\n",
    "class_dict = {\n",
    "    'red blood cell':0,\n",
    "    'trophozoite': 1, \n",
    "    'schizont': 2, \n",
    "    'difficult': 3, \n",
    "    'ring': 4,\n",
    "    'leukocyte': 5, \n",
    "    'gametocyte': 6\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes count : 7\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8          # packets count\n",
    "\n",
    "size = 416              # size of resize image\n",
    "yolo_max_boxes = 223    # maximum yolo boxes predicted per image (if there are less, the others will be filled with zeros)\n",
    "\n",
    "yolo_iou_threshold = 0.5        # IOU threshold score \n",
    "yolo_score_threshold = 0.4      # objectness threshold score\n",
    "learning_rate = 1e-4            # learning rate\n",
    "epochs = 100                    # epochs run to fine tune our model\n",
    "\n",
    "# YOLO anchors\n",
    "yolo_anchors = np.array([(10, 13), (16, 30), (33, 23), (30, 61), (62, 45),\n",
    "                         (59, 119), (116, 90), (156, 198), (373, 326)],\n",
    "                        np.float32) / size\n",
    "# YOLO masks\n",
    "yolo_anchor_masks = np.array([[6, 7, 8], [3, 4, 5], [0, 1, 2]])\n",
    "\n",
    "classes_count = len(class_dict.items()) # categories count\n",
    "print(f'Classes count : {classes_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Darknet**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Darknet layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolution layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DarknetConv(x : tf.Tensor, \n",
    "                filters: int, \n",
    "                size : int, \n",
    "                strides: int = 1, \n",
    "                batch_norm: bool = True) -> tf.Tensor:\n",
    "    \n",
    "    if strides == 1:\n",
    "        # all-way padding\n",
    "        padding = 'same'\n",
    "    else:\n",
    "        # top left half-padding\n",
    "        x = ZeroPadding2D(((1, 0), (1, 0)))(x) \n",
    "        padding = 'valid' \n",
    "    \n",
    "    # 2D convolution layer \n",
    "    x = Conv2D(filters=filters, kernel_size=size,\n",
    "               strides=strides, padding=padding,\n",
    "               use_bias=not batch_norm, kernel_regularizer=l2(0.0005))(x)\n",
    "    \n",
    "    if batch_norm:\n",
    "        # batch normalization layer\n",
    "        x = BatchNormalization()(x)\n",
    "        \n",
    "        # Leaky ReLU layer\n",
    "        # -- negatives values reduction to 10%\n",
    "        x = LeakyReLU(alpha=0.1)(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Residual layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DarknetResidual(x: tf.Tensor, filters: int) -> tf.Tensor:\n",
    "    prev : tf.Tensor = x\n",
    "\n",
    "    # two convolutions\n",
    "    # -- first layer\n",
    "    if filters % 2 != 0:\n",
    "        x = DarknetConv(x, filters, 1) \n",
    "    else:\n",
    "        x = DarknetConv(x, filters // 2, 1)\n",
    "\n",
    "    # -- second layer\n",
    "    x = DarknetConv(x, filters, 3)\n",
    "\n",
    "    # tensors sum\n",
    "    # -- prev : initial input tensor\n",
    "    # -- x    : output tensor from convolution layers\n",
    "    x = Add()([prev, x])\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Block superlayer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DarknetBlock(x, filters: int, repeat: int) -> tf.Tensor:\n",
    "    # initial convolution layer\n",
    "    x = DarknetConv(x, filters, size=3, strides=2) \n",
    "\n",
    "    # residual layers (in count of `repeat`)\n",
    "    for _ in range(repeat):\n",
    "        x = DarknetResidual(x, filters)\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Darknet builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CNN architecture schematic**\n",
    "\n",
    "![darknet-architecture-schematic](../../assets/darkent-architecture-schematics.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network - Darknet Architecture\n",
    "def Darknet(name: str | None = None) -> Model:\n",
    "    # input load\n",
    "    x = inputs = Input([None, None, 3])\n",
    "\n",
    "    # initial convolution layer\n",
    "    x = DarknetConv(x, filters=32, strides=3)\n",
    "\n",
    "    # darknet residual blocks\n",
    "\n",
    "    x = DarknetBlock(x, filters=64, repeat=1)\n",
    "\n",
    "    x = DarknetBlock(x, filters=128, repeat=2)\n",
    "\n",
    "    # -- -- outputs - 1st dimension\n",
    "    x = x_36 = DarknetBlock(x, filters=256, repeat=8)\n",
    "    \n",
    "    # -- -- outputs - 2nd dimension\n",
    "    x = x_61 = DarknetBlock(x, filters=512, repeat=8)\n",
    "\n",
    "    # -- -- outputs - 3rd dimension\n",
    "    x = DarknetBlock(x, filters=1024, repeat=4)\n",
    "\n",
    "    # group of layers with training interface\n",
    "    # -- inputs  : base layer\n",
    "    return Model(inputs, (x_36, x_61, x), name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Yolo v3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Yolo Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Boxes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_boxes(pred: tf.Tensor, anchors: np.array, classes: int):\n",
    "    # grid size\n",
    "    grid_size = tf.shape(pred)[1]\n",
    "\n",
    "    # split tensor into a list of subtensors\n",
    "    # -- `box_xy` : bounding box grids tensor (x, y)\n",
    "    # -- `box_wh` : bounding box dimensions tensot(width, height)\n",
    "    # -- `objectness`  : objectness score tensor\n",
    "    # -- `class_probs` : class probabilities tensor\n",
    "    box_xy, box_wh, objectness, class_probs = tf.split(\n",
    "        pred, (2, 2, 1, classes), axis=-1)\n",
    "\n",
    "    # apply sigmoid function to normalize outputs\n",
    "    box_xy = tf.sigmoid(box_xy) \n",
    "    objectness = tf.sigmoid(objectness)\n",
    "    class_probs = tf.sigmoid(class_probs)\n",
    "\n",
    "    # concatenate box coordinates and dimensions\n",
    "    pred_box = tf.concat((box_xy, box_wh), axis=-1)\n",
    "\n",
    "    # create a `grid` to map the coordinates of the boxes\n",
    "    grid = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))\n",
    "    \n",
    "    # expand dimensions of `grid` for further operations\n",
    "    grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)\n",
    "\n",
    "    # convert `grid` and `grid_size` to `float32` for mathematical operations\n",
    "    grid = tf.cast(grid, tf.float32)\n",
    "    grid_size = tf.cast(grid_size, tf.float32)\n",
    "\n",
    "    # adjust box coordinates to the grid size\n",
    "    # -- transoform the box coordinates to the actual position on the image\n",
    "    box_xy = (box_xy + grid / grid_size)\n",
    "    \n",
    "    # adjust box dimensions using the anchors\n",
    "    # -- scale the width and height of the boxes using the anchor boxes\n",
    "    box_wh = tf.exp(box_wh) * anchors\n",
    "\n",
    "    # calculate the coordinates of the upper left and bottom right corners of the boxes\n",
    "    box_x1y1 = box_xy - box_wh / 2 \n",
    "    box_x2y2 = box_xy + box_wh / 2\n",
    "    \n",
    "    # concatenate the corner coordinates to form the final bounding boxes\n",
    "    bbox = tf.concat([box_x1y1, box_x2y2], axis=-1)\n",
    "\n",
    "    return bbox, objectness, class_probs, pred_box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Non max suppression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_nms(outputs):\n",
    "\n",
    "    # `b` : boxes\n",
    "    # `c` : confidences\n",
    "    # `t` : class probabilities\n",
    "    b, c, t = [], [], []\n",
    "\n",
    "    # iterating through each outputs predicted by model\n",
    "    for out in outputs:\n",
    "        b.append(tf.reshape(out[0], (tf.shape(out[0])[0], -1, tf.shape(out[0])[-1])))\n",
    "        c.append(tf.reshape(out[1], (tf.shape(out[1])[0], -1, tf.shape(out[1])[-1])))\n",
    "        t.append(tf.reshape(out[2], (tf.shape(out[2])[0], -1, tf.shape(out[2])[-1])))\n",
    "\n",
    "    # list concatenatation into the whole tensors \n",
    "    bbox = tf.concat(b, axis=1)\n",
    "    confidence = tf.concat(c, axis=1)\n",
    "    class_probs = tf.concat(t, axis=1)\n",
    "\n",
    "    # `scores` : product of confidence and probabilities\n",
    "    # -- final trust score for each class and box\n",
    "    scores = confidence * class_probs\n",
    "    \n",
    "    # Non-Maximum Suppression\n",
    "    # -- eliminates overlapped boxes with selecting the most trusted ones\n",
    "    boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\n",
    "        boxes=tf.reshape(bbox, (tf.shape(bbox)[0], -1, 1, 4)),\n",
    "        scores=tf.reshape(scores, (tf.shape(scores)[0], -1, tf.shape(scores)[-1])),\n",
    "        max_output_size_per_class = yolo_max_boxes,\n",
    "        max_total_size = yolo_max_boxes,\n",
    "        iou_threshold = yolo_iou_threshold,\n",
    "        score_threshold = yolo_score_threshold\n",
    "    )\n",
    "\n",
    "    # return filtered boxes, class scores, class labels and valid detections count\n",
    "    return boxes, scores, classes, valid_detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intersection over Union**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def broadcast_iou(box_1: tf.Tensor, box_2: tf.Tensor):\n",
    "    # expand dimensions of the boxes for further broadcasting\n",
    "    box_1 = tf.expand_dims(box_1, -2)\n",
    "    box_2 = tf.expand_dims(box_2, 0)\n",
    "    \n",
    "    # boxes' new shapes calculation\n",
    "    new_shape = tf.broadcast_dynamic_shape(tf.shape(box_1), tf.shape(box_2))\n",
    "\n",
    "    # boxes broadcasting - reshape for further numerical operations\n",
    "    box_1 = tf.broadcast_to(box_1, new_shape)\n",
    "    box_2 = tf.broadcast_to(box_2, new_shape)\n",
    "\n",
    "    # intersection width and height calculation\n",
    "    int_w = tf.maximum(tf.minimum(box_1[..., 2], box_2[..., 2]) -\n",
    "                       tf.maximum(box_1[..., 0], box_2[..., 0]), 0) \n",
    "    int_h = tf.maximum(tf.minimum(box_1[..., 3], box_2[..., 3]) -\n",
    "                       tf.maximum(box_1[..., 1], box_2[..., 1]), 0) \n",
    "\n",
    "    # intersection area surface calculation\n",
    "    int_area = int_w * int_h \n",
    "    \n",
    "    # boxes area surface calculation\n",
    "    box_1_area = (box_1[..., 2] - box_1[..., 0]) * (box_1[..., 3] - box_1[..., 1])\n",
    "    box_2_area = (box_2[..., 2] - box_2[..., 0]) * (box_2[..., 3] - box_2[..., 1])\n",
    "\n",
    "    # Formula: Union(A,B) = A + B - Intersection(A,B)\n",
    "    return int_area / (box_1_area + box_2_area - int_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Yolo Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def YoloConv(filters: int, name : str | None = None):\n",
    "    \n",
    "    def yolo_conv(x_in: tf.Tensor | tuple):\n",
    "        if isinstance(x_in, tuple):\n",
    "            # if input is a tuple, connect the streams\n",
    "            inputs = Input(x_in[0].shape[1:]), Input(x_in[1].shape[1:])\n",
    "\n",
    "            # remember initial input\n",
    "            x, x_skip = inputs\n",
    "\n",
    "            # process input with convolution layer\n",
    "            x = DarknetConv(x, filters, 1)\n",
    "            \n",
    "            # enlarge tensor\n",
    "            x = UpSampling2D(2)(x)\n",
    "            \n",
    "            # and concatenate with remembered initial input\n",
    "            x = Concatenate()([x, x_skip])\n",
    "        else:\n",
    "            # otherwise - do not perform the streams connecting\n",
    "            x = inputs = Input(x_in.shape[1:])\n",
    "        \n",
    "        # alternating convolution layers\n",
    "        # -- filters | kernel sizes\n",
    "        # -- 3x |  f  | 1\n",
    "        # -- 2x | 2*f | 3\n",
    "        x = DarknetConv(x, filters=filters,      size=1)\n",
    "        x = DarknetConv(x, filters=filters * 2,  size=3)\n",
    "        x = DarknetConv(x, filters=filters,      size=1)\n",
    "        x = DarknetConv(x, filters=filters * 2,  size=3)\n",
    "        x = DarknetConv(x, filters=filters,      size=1)\n",
    "        \n",
    "        return Model(inputs, x, name=name)(x_in)\n",
    "    \n",
    "    return yolo_conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Yolo Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def YoloOutput(filters: int, \n",
    "               anchors: np.array, \n",
    "               classes: int, \n",
    "               name: str | None = None):\n",
    "    \n",
    "    def yolo_output(x_in: tf.Tensor):\n",
    "        # load input according to initial tensor shape\n",
    "        x = inputs = Input(x_in.shape[1:])\n",
    "\n",
    "        # convolution layer with doubled filters\n",
    "        x = DarknetConv(x, filters=filters * 2, size=3)\n",
    "        \n",
    "        # second convolution layer\n",
    "        # -- filters : anchors * (classes + 5)\n",
    "        # -- kernel size : 1\n",
    "        # -- `classes + 5` : class labels [`classes`], boxes info [4], objectness [1]\n",
    "        x = DarknetConv(x, filters=anchors * (classes + 5), size=1, batch_norm=False)\n",
    "        \n",
    "        # tensor reshape into shape of last convolution \n",
    "        x = Lambda(lambda x: tf.reshape(x, (-1, tf.shape(x)[1], tf.shape(x)[2], \n",
    "                                            anchors, classes + 5)))(x)\n",
    "\n",
    "        return Model(inputs, x, name=name)(x_in)\n",
    "    \n",
    "    return yolo_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Yolo Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def YoloLoss(anchors, classes=80, ignore_thresh=0.5):\n",
    "    def yolo_loss(y_true, y_pred):\n",
    "        \n",
    "        # `pred_box`  : \n",
    "        # `pred_obj`  : \n",
    "        # `pred_xywh` : \n",
    "        pred_box, pred_obj, pred_class, pred_xywh = yolo_boxes(\n",
    "            y_pred, anchors, classes)\n",
    "        \n",
    "        # predicted bounding boxes grids[x, y] and dimensions[width, heigth] calculation\n",
    "        pred_xy = pred_xywh[..., 0:2]\n",
    "        pred_wh = pred_xywh[..., 2:4]\n",
    "\n",
    "        # 2. transform all true outputs\n",
    "        \n",
    "        true_box, true_obj, true_class_idx = tf.split(\n",
    "            y_true, (4, 1, 1), axis=-1) \n",
    "\n",
    "        true_xy = (true_box[..., 0:2] + true_box[..., 2:4]) / 2 # finding center (Xcen,Ycen)\n",
    "        true_wh = true_box[..., 2:4] - true_box[..., 0:2] # width and height\n",
    "\n",
    "        box_loss_scale = 2 - true_wh[..., 0] * true_wh[..., 1]\n",
    "\n",
    "        # 3. inverting the pred box equations\n",
    "        grid_size = tf.shape(y_true)[1]\n",
    "        grid = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))\n",
    "        grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)\n",
    "        true_xy = true_xy * tf.cast(grid_size, tf.float32) - \\\n",
    "            tf.cast(grid, tf.float32)\n",
    "\n",
    "        true_wh = tf.math.log(true_wh / anchors) \n",
    "        true_wh = tf.where(tf.math.is_inf(true_wh),\n",
    "                           tf.zeros_like(true_wh), true_wh)\n",
    "\n",
    "        # 4. calculate all masks\n",
    "        obj_mask = tf.squeeze(true_obj, -1)\n",
    "        \n",
    "        best_iou = tf.map_fn(\n",
    "            lambda x: tf.reduce_max(broadcast_iou(x[0], tf.boolean_mask(\n",
    "                x[1], tf.cast(x[2], tf.bool))), axis=-1),\n",
    "            (pred_box, true_box, obj_mask),\n",
    "            tf.float32)\n",
    "        ignore_mask = tf.cast(best_iou < ignore_thresh, tf.float32)\n",
    "\n",
    "        # 5. calculate all losses\n",
    "        xy_loss = obj_mask * box_loss_scale * \\\n",
    "            tf.reduce_sum(tf.square(true_xy - pred_xy), axis=-1)\n",
    "        wh_loss = obj_mask * box_loss_scale * \\\n",
    "            tf.reduce_sum(tf.square(true_wh - pred_wh), axis=-1)\n",
    "        \n",
    "        obj_loss = binary_crossentropy(true_obj, pred_obj)\n",
    "        \n",
    "        \n",
    "        alpha = 0.85\n",
    "        conf_focal = tf.pow(obj_mask-tf.squeeze(tf.sigmoid(pred_obj),-1),2)\n",
    "        obj_loss = conf_focal*((1-alpha)*obj_mask*obj_loss + alpha*(1-obj_mask)*ignore_mask*obj_loss)\n",
    "\n",
    "        class_loss = obj_mask * binary_crossentropy(\n",
    "            true_class_idx, pred_class)\n",
    "\n",
    "        # 6. sum over (batch, gridx, gridy, anchors) => (batch, 1)\n",
    "        xy_loss = tf.reduce_sum(xy_loss, axis=(1, 2, 3))\n",
    "        wh_loss = tf.reduce_sum(wh_loss, axis=(1, 2, 3))\n",
    "        obj_loss = tf.reduce_sum(obj_loss, axis=(1, 2, 3))\n",
    "        class_loss = tf.reduce_sum(class_loss, axis=(1, 2, 3))\n",
    "\n",
    "        return xy_loss + wh_loss + obj_loss + class_loss\n",
    "    \n",
    "    return yolo_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Yolo Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Yolo(size: int | None = None, \n",
    "         channels: int = 3, \n",
    "         anchors : np.array = yolo_anchors,\n",
    "         masks: np.array = yolo_anchor_masks, \n",
    "         classes: int = 80, \n",
    "         training: bool = False):\n",
    "    \n",
    "    # load input data : image pixel matrixes (by each channel)\n",
    "    x = inputs = Input([size, size, channels], name='input')\n",
    "\n",
    "    # CNN Backbone\n",
    "    x_36, x_61, x = Darknet(name='yolo_darknet')(x)\n",
    "\n",
    "    # YOLO convolution layers at 3 levels\n",
    "    # -- filters : 512\n",
    "    x = YoloConv(512, name='yolo_conv_0')(x) \n",
    "    output_0 = YoloOutput(512, len(masks[0]), classes, name='yolo_output_0')(x)\n",
    "    \n",
    "    # -- filters : 256\n",
    "    # -- -- up scaled with `x_61`\n",
    "    x = YoloConv(256, name='yolo_conv_1')((x, x_61))\n",
    "    output_1 = YoloOutput(256, len(masks[1]), classes, name='yolo_output_1')(x)\n",
    "\n",
    "    # -- filters : 128\n",
    "    # -- -- up scaled with `x_36`\n",
    "    x = YoloConv(128, name='yolo_conv_2')((x, x_36))\n",
    "    output_2 = YoloOutput(128, len(masks[2]), classes, name='yolo_output_2')(x)\n",
    "\n",
    "    # if model is expected to be trained\n",
    "    if training:\n",
    "        return Model(inputs, (output_0, output_1, output_2), name='yolov3')\n",
    "\n",
    "    else:\n",
    "        # assumed boxes at convolution layers at 3 scale levels\n",
    "        # -- level : 0\n",
    "        boxes_0 = Lambda(lambda x: yolo_boxes(x, anchors[masks[0]], classes),\n",
    "                         name='yolo_boxes_0')(output_0)\n",
    "        # -- level : 1\n",
    "        boxes_1 = Lambda(lambda x: yolo_boxes(x, anchors[masks[1]], classes),\n",
    "                         name='yolo_boxes_1')(output_1)\n",
    "        # -- level : 3\n",
    "        boxes_2 = Lambda(lambda x: yolo_boxes(x, anchors[masks[2]], classes),\n",
    "                         name='yolo_boxes_2')(output_2)\n",
    "\n",
    "        # prediction outputs\n",
    "        outputs = Lambda(lambda x: yolo_nms(x, anchors, masks, classes),\n",
    "                         name='yolo_nms')((boxes_0[:3], boxes_1[:3], boxes_2[:3]))\n",
    "\n",
    "        return Model(inputs, outputs, name='yolov3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Core utils**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Darknet weights loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_darknet_weights(model: Model, weights_file: str, tiny: bool = False):\n",
    "    # File open\n",
    "    wf = open(weights_file, 'rb')\n",
    "    \n",
    "    # Skip first 5 values\n",
    "    major, minor, revision, seen, _ = np.fromfile(wf, dtype=np.int32, count=5)\n",
    "\n",
    "    layers = ['yolo_darknet',\n",
    "              'yolo_conv_0', 'yolo_output_0',\n",
    "              'yolo_conv_1', 'yolo_output_1', \n",
    "              'yolo_conv_2', 'yolo_output_2']\n",
    "\n",
    "    for layer_name in layers:\n",
    "        sub_model = model.get_layer(layer_name)\n",
    "        for i, layer in enumerate(sub_model.layers):\n",
    "            if not layer.name.startswith('conv2d'): \n",
    "                continue\n",
    "            batch_norm = None\n",
    "            if i + 1 < len(sub_model.layers) and \\\n",
    "                    sub_model.layers[i + 1].name.startswith('batch_norm'):\n",
    "                batch_norm = sub_model.layers[i + 1]\n",
    "\n",
    "            logging.info(\"{}/{} {}\".format(\n",
    "                sub_model.name, layer.name, 'bn' if batch_norm else 'bias'))\n",
    "\n",
    "            filters = layer.filters\n",
    "            size = layer.kernel_size[0]\n",
    "            in_dim = layer.input_shape[-1]\n",
    "\n",
    "            if batch_norm is None:\n",
    "                conv_bias = np.fromfile(wf, dtype=np.float32, count=filters)\n",
    "            else:\n",
    "                bn_weights = np.fromfile(\n",
    "                    wf, dtype=np.float32, count=4 * filters)\n",
    "                bn_weights = bn_weights.reshape((4, filters))[[1, 0, 2, 3]]\n",
    "\n",
    "            conv_shape = (filters, in_dim, size, size)\n",
    "            conv_weights = np.fromfile(\n",
    "                wf, dtype=np.float32, count=np.product(conv_shape))\n",
    "            conv_weights = conv_weights.reshape(\n",
    "                conv_shape).transpose([2, 3, 1, 0])\n",
    "\n",
    "            if batch_norm is None:\n",
    "                layer.set_weights([conv_weights, conv_bias])\n",
    "            else:\n",
    "                layer.set_weights([conv_weights])\n",
    "                batch_norm.set_weights(bn_weights)\n",
    "\n",
    "    assert len(wf.read()) == 0, 'failed to read all data'\n",
    "    wf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outputs drawer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_outputs(img, outputs, class_names,no_rbc = True):\n",
    "    boxes, objectness, classes, nums = outputs # predicted outputs extraction\n",
    "    boxes, objectness, classes, nums = boxes[0], objectness[0], classes[0], nums[0]\n",
    "    wh = np.flip(img.shape[0:2])\n",
    "\n",
    "    for i in range(nums):\n",
    "        if no_rbc:\n",
    "            if classes[i]==0:\n",
    "                continue \n",
    "            \n",
    "        x1y1 = tuple((np.array(boxes[i][0:2]) * wh).astype(np.int32))\n",
    "        x2y2 = tuple((np.array(boxes[i][2:4]) * wh).astype(np.int32))\n",
    "        img = cv2.rectangle(img, x1y1, x2y2, (255, 0, 0), 2)\n",
    "        img = cv2.putText(img, '{} {:.4f}'.format(\n",
    "            class_names[int(classes[i])], objectness[i]),\n",
    "            x1y1, cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 2)\n",
    "        \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model freezer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_all(model: Model, frozen: bool = True):\n",
    "    # set `trainable` attribute for the model and recursively for its each layer \n",
    "    model.trainable = not frozen\n",
    "\n",
    "    # recursively freeze all sublayers for each model layer\n",
    "    for layer in model.layers:\n",
    "        freeze_all(layer, frozen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dataset(data: pd.DataFrame, \n",
    "                  class_dict: dict, \n",
    "                  size: int,\n",
    "                  image_path: str, \n",
    "                  images_dirpath: str, \n",
    "                  yolo_max_boxes: int):\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    # for each image in directory\n",
    "    for img in tqdm(image_path):\n",
    "        # image load\n",
    "        x_train = Image.open(images_dirpath + img)\n",
    "        \n",
    "        # image size\n",
    "        width, height = x_train.size\n",
    "\n",
    "        # image resize to specified square resolution\n",
    "        x_train = x_train.resize((size, size))\n",
    "\n",
    "        # cast to Numpy array\n",
    "        x_train = np.array(x_train)\n",
    "\n",
    "        temp_data = []\n",
    "        # for each object at the image\n",
    "        for _,row in data[data['img_path']==image_path+img].iterrows():\n",
    "            # calculate the upper left and bottom right corners grids of the box\n",
    "            x_min = row.min_c / width\n",
    "            x_max = row.max_c / width\n",
    "            y_min = row.min_r / height\n",
    "            y_max = row.max_r / height\n",
    "            \n",
    "            # get the object category label\n",
    "            category = class_dict[row.category]\n",
    "            \n",
    "            # store single object info as an array \n",
    "            temp_data.append([x_min, y_min, x_max, y_max, category])\n",
    "        \n",
    "        # expand output tensor shape to `yolo_max_boxes` and fill with zeros\n",
    "        temp_data = temp_data + [[0,0,0,0,0]] * (yolo_max_boxes - len(temp_data))\n",
    "\n",
    "        # add expected output data\n",
    "        Y.append(temp_data)\n",
    "        # add training input data\n",
    "        X.append(x_train)\n",
    "    \n",
    "    # for each input stack the output data and return this matrix\n",
    "    return (np.array(X),np.stack(np.array(Y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_images(x: tf.Tensor, size: int):\n",
    "    # resize images to specified square size\n",
    "    x = tf.image.resize(x,(size,size))\n",
    "    \n",
    "    # normalize values to range <0.0, 1.0>\n",
    "    x = x / 255.0\n",
    "    \n",
    "    return (x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
