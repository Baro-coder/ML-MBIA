{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# -- Core\n",
    "import time\n",
    "import datetime\n",
    "import logging\n",
    "\n",
    "# -- TQDM\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -- OpenCV\n",
    "import cv2\n",
    "\n",
    "# -- Numpy\n",
    "import numpy as np\n",
    "\n",
    "# -- Tensorflow and Keras\n",
    "import tensorflow as tf\n",
    "from keras import Model\n",
    "from keras.layers import Add, Concatenate, Conv2D, Input, Lambda, LeakyReLU, MaxPool2D, UpSampling2D, ZeroPadding2D, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Globals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "DATA_DIR = '../../data'\n",
    "\n",
    "# Images info CSV file\n",
    "ALL_DATA_CSV_FILEPATH = f'{DATA_DIR}/all-data.csv'\n",
    "\n",
    "# Cell classes dictionary\n",
    "class_dict = {\n",
    "    'red blood cell':0,\n",
    "    'trophozoite': 1, \n",
    "    'schizont': 2, \n",
    "    'difficult': 3, \n",
    "    'ring': 4,\n",
    "    'leukocyte': 5, \n",
    "    'gametocyte': 6\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initializing variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes count : 7\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8          # packets count\n",
    "\n",
    "size = 416              # size of resize image\n",
    "yolo_max_boxes = 223    # maximum yolo boxes predicted per image (if there are less, the others will be filled with zeros)\n",
    "\n",
    "yolo_iou_threshold = 0.5        # IOU threshold score \n",
    "yolo_score_threshold = 0.4      # objectness threshold score\n",
    "learning_rate = 1e-4            # learning rate\n",
    "epochs = 100                    # epochs run to fine tune our model\n",
    "\n",
    "# YOLO anchors\n",
    "yolo_anchors = np.array([(10, 13), (16, 30), (33, 23), (30, 61), (62, 45),\n",
    "                         (59, 119), (116, 90), (156, 198), (373, 326)],\n",
    "                        np.float32) / size\n",
    "# YOLO masks\n",
    "yolo_anchor_masks = np.array([[6, 7, 8], [3, 4, 5], [0, 1, 2]])\n",
    "\n",
    "classes_count = len(class_dict.items()) # categories count\n",
    "print(f'Classes count : {classes_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Darknet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Darknet layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DarknetConv(x : tf.Tensor, \n",
    "                filters: int, \n",
    "                size : int, \n",
    "                strides: int = 1, \n",
    "                batch_norm: bool = True) -> tf.Tensor:\n",
    "    \n",
    "    if strides == 1:\n",
    "        # all-way padding\n",
    "        padding = 'same'\n",
    "    else:\n",
    "        # top left half-padding\n",
    "        x = ZeroPadding2D(((1, 0), (1, 0)))(x) \n",
    "        padding = 'valid' \n",
    "    \n",
    "    # convolution layer \n",
    "    x = Conv2D(filters=filters, kernel_size=size,\n",
    "               strides=strides, padding=padding,\n",
    "               use_bias=not batch_norm, kernel_regularizer=l2(0.0005))(x)\n",
    "    \n",
    "    if batch_norm:\n",
    "        # normalization\n",
    "        x = BatchNormalization()(x)\n",
    "        # activation with ReLu\n",
    "        # -- negatives values reduction to 10%\n",
    "        x = LeakyReLU(alpha=0.1)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "# Residual Connection Layer\n",
    "def DarknetResidual(x: tf.Tensor, filters: int) -> tf.Tensor:\n",
    "    prev : tf.Tensor = x\n",
    "\n",
    "    # two convolutions\n",
    "    # -- first layer\n",
    "    if filters % 2 != 0:\n",
    "        x = DarknetConv(x, filters, 1) \n",
    "    else:\n",
    "        x = DarknetConv(x, filters // 2, 1)\n",
    "\n",
    "    # -- second layer\n",
    "    x = DarknetConv(x, filters, 3)\n",
    "\n",
    "    # tensors sum\n",
    "    # -- prev : initial input tensor\n",
    "    # -- x    : output tensor from convolution layers\n",
    "    x = Add()([prev, x])\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "# Darknet block function \n",
    "def DarknetBlock(x, filters: int, blocks: int) -> tf.Tensor:\n",
    "    # initial convolution layer\n",
    "    x = DarknetConv(x, filters, size=3, strides=2) \n",
    "\n",
    "    # residual layers (in count of `blocks`)\n",
    "    for _ in range(blocks):\n",
    "        x = DarknetResidual(x, filters)\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Darknet builder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network - Darknet Architecture\n",
    "def Darknet(name: str | None = None) -> Model:\n",
    "    # input load\n",
    "    x = inputs = Input([None, None, 3])\n",
    "\n",
    "    # initial convolution layer\n",
    "    x = DarknetConv(x, filters=32, strides=3)\n",
    "\n",
    "    # darknet residual blocks\n",
    "\n",
    "    x = DarknetBlock(x, filters=64, blocks=1)\n",
    "\n",
    "    x = DarknetBlock(x, filters=128, blocks=2)\n",
    "\n",
    "    # -- -- outputs - 1st dimension\n",
    "    x = x_36 = DarknetBlock(x, filters=256, blocks=8)\n",
    "    \n",
    "    # -- -- outputs - 2nd dimension\n",
    "    x = x_61 = DarknetBlock(x, filters=512, blocks=8)\n",
    "\n",
    "    # -- -- outputs - 3rd dimension\n",
    "    x = DarknetBlock(x, filters=1024, blocks=4)\n",
    "\n",
    "    # group of layers with training interface\n",
    "    # -- inputs  : base layer\n",
    "    return Model(inputs, (x_36, x_61, x), name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yolo v3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Yolo Utils**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_boxes(pred, anchors, classes):\n",
    "    # grid size\n",
    "    grid_size = tf.shape(pred)[1]\n",
    "\n",
    "    # split tensor into a list of subtensors\n",
    "    box_xy, box_wh, objectness, class_probs = tf.split(\n",
    "        pred, (2, 2, 1, classes), axis=-1)\n",
    "\n",
    "    box_xy = tf.sigmoid(box_xy) \n",
    "    objectness = tf.sigmoid(objectness)\n",
    "    class_probs = tf.sigmoid(class_probs)\n",
    "    pred_box = tf.concat((box_xy, box_wh), axis=-1)\n",
    "\n",
    "    grid = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))\n",
    "    grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)\n",
    "\n",
    "    box_xy = (box_xy + tf.cast(grid, tf.float32)) / tf.cast(grid_size, tf.float32)\n",
    "    box_wh = tf.exp(box_wh) * anchors\n",
    "\n",
    "    box_x1y1 = box_xy - box_wh / 2 \n",
    "    box_x2y2 = box_xy + box_wh / 2\n",
    "    bbox = tf.concat([box_x1y1, box_x2y2], axis=-1)\n",
    "\n",
    "    return bbox, objectness, class_probs, pred_box\n",
    "\n",
    "def yolo_nms(outputs, anchors, masks, classes):\n",
    "\n",
    "    b, c, t = [], [], []\n",
    "\n",
    "    # iterating through each outputs predicted by model\n",
    "    for o in outputs:\n",
    "        b.append(tf.reshape(o[0], (tf.shape(o[0])[0], -1, tf.shape(o[0])[-1])))\n",
    "        c.append(tf.reshape(o[1], (tf.shape(o[1])[0], -1, tf.shape(o[1])[-1])))\n",
    "        t.append(tf.reshape(o[2], (tf.shape(o[2])[0], -1, tf.shape(o[2])[-1])))\n",
    "\n",
    "    bbox = tf.concat(b, axis=1)\n",
    "    confidence = tf.concat(c, axis=1)\n",
    "    class_probs = tf.concat(t, axis=1)\n",
    "\n",
    "    scores = confidence * class_probs\n",
    "    \n",
    "    boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\n",
    "        boxes=tf.reshape(bbox, (tf.shape(bbox)[0], -1, 1, 4)),\n",
    "        scores=tf.reshape(\n",
    "            scores, (tf.shape(scores)[0], -1, tf.shape(scores)[-1])),\n",
    "        max_output_size_per_class = yolo_max_boxes,\n",
    "        max_total_size = yolo_max_boxes,\n",
    "        iou_threshold = yolo_iou_threshold,\n",
    "        score_threshold = yolo_score_threshold\n",
    "    )\n",
    "\n",
    "    return boxes, scores, classes, valid_detections\n",
    "\n",
    "# Intersection over Union ratio calculation function\n",
    "def broadcast_iou(box_1, box_2):\n",
    "    box_1 = tf.expand_dims(box_1, -2)\n",
    "    box_2 = tf.expand_dims(box_2, 0)\n",
    "    \n",
    "    new_shape = tf.broadcast_dynamic_shape(tf.shape(box_1), tf.shape(box_2))\n",
    "    box_1 = tf.broadcast_to(box_1, new_shape)\n",
    "    box_2 = tf.broadcast_to(box_2, new_shape)\n",
    "\n",
    "    int_w = tf.maximum(tf.minimum(box_1[..., 2], box_2[..., 2]) -\n",
    "                       tf.maximum(box_1[..., 0], box_2[..., 0]), 0) \n",
    "    int_h = tf.maximum(tf.minimum(box_1[..., 3], box_2[..., 3]) -\n",
    "                       tf.maximum(box_1[..., 1], box_2[..., 1]), 0) \n",
    "    int_area = int_w * int_h \n",
    "    box_1_area = (box_1[..., 2] - box_1[..., 0]) * \\\n",
    "        (box_1[..., 3] - box_1[..., 1])\n",
    "    box_2_area = (box_2[..., 2] - box_2[..., 0]) * \\\n",
    "        (box_2[..., 3] - box_2[..., 1])\n",
    "\n",
    "    # Formula: Union(A,B) = A + B - Inter(A,B)\n",
    "    return int_area / (box_1_area + box_2_area - int_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Yolo Convolution Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO Convolution layer\n",
    "def YoloConv(filters: int, name : str | None = None):\n",
    "    \n",
    "    def yolo_conv(x_in: tf.Tensor | tuple):\n",
    "        if isinstance(x_in, tuple):\n",
    "            # if input is a tuple, split it\n",
    "            inputs = Input(x_in[0].shape[1:]), Input(x_in[1].shape[1:])\n",
    "\n",
    "            # ... into inputs to process and inputs to skip the processing\n",
    "            x, x_skip = inputs\n",
    "\n",
    "            # process the first one\n",
    "            x = DarknetConv(x, filters, 1)\n",
    "            \n",
    "            # enlarge twicely  \n",
    "            x = UpSampling2D(2)(x)\n",
    "            \n",
    "            # and concatenate with unprocessed ones\n",
    "            x = Concatenate()([x, x_skip])\n",
    "        else:\n",
    "            # otherwise - do not process\n",
    "            x = inputs = Input(x_in.shape[1:])\n",
    "        \n",
    "        # alternating convolution layers\n",
    "        # -- filters | strides\n",
    "        # --  f | 1\n",
    "        # -- 2f | 3\n",
    "        x = DarknetConv(x, filters=filters,      size=1)\n",
    "        x = DarknetConv(x, filters=filters * 2,  size=3)\n",
    "        x = DarknetConv(x, filters=filters,      size=1)\n",
    "        x = DarknetConv(x, filters=filters * 2,  size=3)\n",
    "        x = DarknetConv(x, filters=filters,      size=1)\n",
    "        \n",
    "        return Model(inputs, x, name=name)(x_in)\n",
    "    \n",
    "    return yolo_conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Yolo Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO Output model\n",
    "def YoloOutput(filters, anchors, classes, name=None):\n",
    "    \n",
    "    def yolo_output(x_in):\n",
    "        # load input\n",
    "        x = inputs = Input(x_in.shape[1:])\n",
    "\n",
    "        # convolution layer with doubled filters and strides equals 3\n",
    "        x = DarknetConv(x, filters * 2, 3)\n",
    "        \n",
    "        # second convolution layer with batch normalization\n",
    "        # -- filters : anchors x (classes + 5)\n",
    "        # -- strides : 1\n",
    "        x = DarknetConv(x, anchors * (classes + 5), 1, batch_norm=False)\n",
    "        \n",
    "        # tensor reshape into shape of last convolution \n",
    "        #   layer output shape[1, 2, `anchors`, `classes + 5`]\n",
    "        # -- 1, 2 : pixels\n",
    "        # -- `anchors`      : remembered weights\n",
    "        # -- `classes + 5`  : classification probability\n",
    "        x = Lambda(lambda x: tf.reshape(x, (-1, tf.shape(x)[1], tf.shape(x)[2], \n",
    "                                            anchors, classes + 5)))(x)\n",
    "\n",
    "        return Model(inputs, x, name=name)(x_in)\n",
    "    \n",
    "    return yolo_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Yolo Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO Loss function \n",
    "def YoloLoss(anchors, classes=80, ignore_thresh=0.5):\n",
    "    def yolo_loss(y_true, y_pred):\n",
    "        # 1. transform all pred outputs\n",
    "        pred_box, pred_obj, pred_class, pred_xywh = yolo_boxes(\n",
    "            y_pred, anchors, classes)\n",
    "        pred_xy = pred_xywh[..., 0:2]\n",
    "        pred_wh = pred_xywh[..., 2:4]\n",
    "\n",
    "        # 2. transform all true outputs\n",
    "        \n",
    "        true_box, true_obj, true_class_idx = tf.split(\n",
    "            y_true, (4, 1, 1), axis=-1) \n",
    "\n",
    "        true_xy = (true_box[..., 0:2] + true_box[..., 2:4]) / 2 # finding center (Xcen,Ycen)\n",
    "        true_wh = true_box[..., 2:4] - true_box[..., 0:2] # width and height\n",
    "\n",
    "        box_loss_scale = 2 - true_wh[..., 0] * true_wh[..., 1]\n",
    "\n",
    "        # 3. inverting the pred box equations\n",
    "        grid_size = tf.shape(y_true)[1]\n",
    "        grid = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))\n",
    "        grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)\n",
    "        true_xy = true_xy * tf.cast(grid_size, tf.float32) - \\\n",
    "            tf.cast(grid, tf.float32)\n",
    "\n",
    "        true_wh = tf.math.log(true_wh / anchors) \n",
    "        true_wh = tf.where(tf.math.is_inf(true_wh),\n",
    "                           tf.zeros_like(true_wh), true_wh)\n",
    "\n",
    "        # 4. calculate all masks\n",
    "        obj_mask = tf.squeeze(true_obj, -1)\n",
    "        \n",
    "        best_iou = tf.map_fn(\n",
    "            lambda x: tf.reduce_max(broadcast_iou(x[0], tf.boolean_mask(\n",
    "                x[1], tf.cast(x[2], tf.bool))), axis=-1),\n",
    "            (pred_box, true_box, obj_mask),\n",
    "            tf.float32)\n",
    "        ignore_mask = tf.cast(best_iou < ignore_thresh, tf.float32)\n",
    "\n",
    "        # 5. calculate all losses\n",
    "        xy_loss = obj_mask * box_loss_scale * \\\n",
    "            tf.reduce_sum(tf.square(true_xy - pred_xy), axis=-1)\n",
    "        wh_loss = obj_mask * box_loss_scale * \\\n",
    "            tf.reduce_sum(tf.square(true_wh - pred_wh), axis=-1)\n",
    "        \n",
    "        obj_loss = binary_crossentropy(true_obj, pred_obj)\n",
    "        \n",
    "        \n",
    "        alpha = 0.85\n",
    "        conf_focal = tf.pow(obj_mask-tf.squeeze(tf.sigmoid(pred_obj),-1),2)\n",
    "        obj_loss = conf_focal*((1-alpha)*obj_mask*obj_loss + alpha*(1-obj_mask)*ignore_mask*obj_loss)\n",
    "\n",
    "        class_loss = obj_mask * binary_crossentropy(\n",
    "            true_class_idx, pred_class)\n",
    "\n",
    "        # 6. sum over (batch, gridx, gridy, anchors) => (batch, 1)\n",
    "        xy_loss = tf.reduce_sum(xy_loss, axis=(1, 2, 3))\n",
    "        wh_loss = tf.reduce_sum(wh_loss, axis=(1, 2, 3))\n",
    "        obj_loss = tf.reduce_sum(obj_loss, axis=(1, 2, 3))\n",
    "        class_loss = tf.reduce_sum(class_loss, axis=(1, 2, 3))\n",
    "\n",
    "        return xy_loss + wh_loss + obj_loss + class_loss\n",
    "    \n",
    "    return yolo_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Yolo Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def YoloV3(size=None, channels=3, anchors=yolo_anchors,\n",
    "           masks=yolo_anchor_masks, classes=80, training=False):\n",
    "    \n",
    "    # load input data : image pixel matrixes (by each channel)\n",
    "    x = inputs = Input([size, size, channels], name='input')\n",
    "\n",
    "    # initial Darknet network\n",
    "    x_36, x_61, x = Darknet(name='yolo_darknet')(x)\n",
    "\n",
    "    # YOLO convolution layers at 3 levels\n",
    "    # -- filters : 512\n",
    "    x = YoloConv(512, name='yolo_conv_0')(x) \n",
    "    output_0 = YoloOutput(512, len(masks[0]), classes, name='yolo_output_0')(x)\n",
    "    \n",
    "    # -- filters : 256\n",
    "    # -- -- up scaled with `x_61`\n",
    "    x = YoloConv(256, name='yolo_conv_1')((x, x_61))\n",
    "    output_1 = YoloOutput(256, len(masks[1]), classes, name='yolo_output_1')(x)\n",
    "\n",
    "    # -- filters : 128\n",
    "    # -- -- up scaled with `x_36`\n",
    "    x = YoloConv(128, name='yolo_conv_2')((x, x_36))\n",
    "    output_2 = YoloOutput(128, len(masks[2]), classes, name='yolo_output_2')(x)\n",
    "\n",
    "    # if model is expected to be trained\n",
    "    if training:\n",
    "        return Model(inputs, (output_0, output_1, output_2), name='yolov3')\n",
    "\n",
    "    else:\n",
    "        # assumed boxes at convolution layers at 3 levels\n",
    "        # -- level : 0\n",
    "        boxes_0 = Lambda(lambda x: yolo_boxes(x, anchors[masks[0]], classes),\n",
    "                         name='yolo_boxes_0')(output_0)\n",
    "        # -- level : 1\n",
    "        boxes_1 = Lambda(lambda x: yolo_boxes(x, anchors[masks[1]], classes),\n",
    "                         name='yolo_boxes_1')(output_1)\n",
    "        # -- level : 3\n",
    "        boxes_2 = Lambda(lambda x: yolo_boxes(x, anchors[masks[2]], classes),\n",
    "                         name='yolo_boxes_2')(output_2)\n",
    "\n",
    "        # prediction outputs\n",
    "        outputs = Lambda(lambda x: yolo_nms(x, anchors, masks, classes),\n",
    "                         name='yolo_nms')((boxes_0[:3], boxes_1[:3], boxes_2[:3]))\n",
    "\n",
    "        return Model(inputs, outputs, name='yolov3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utils**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOLOV3_LAYER_LIST = ['yolo_darknet','yolo_conv_0','yolo_output_0','yolo_conv_1',\n",
    "                     'yolo_output_1','yolo_conv_2','yolo_output_2',]\n",
    "\n",
    "# load saved darkent weights\n",
    "def load_darknet_weights(model, weights_file, tiny=False):\n",
    "    wf = open(weights_file, 'rb')\n",
    "    major, minor, revision, seen, _ = np.fromfile(wf, dtype=np.int32, count=5)\n",
    "\n",
    "    layers = YOLOV3_LAYER_LIST\n",
    "\n",
    "    for layer_name in layers:\n",
    "        sub_model = model.get_layer(layer_name)\n",
    "        for i, layer in enumerate(sub_model.layers):\n",
    "            if not layer.name.startswith('conv2d'): \n",
    "                continue\n",
    "            batch_norm = None\n",
    "            if i + 1 < len(sub_model.layers) and \\\n",
    "                    sub_model.layers[i + 1].name.startswith('batch_norm'):\n",
    "                batch_norm = sub_model.layers[i + 1]\n",
    "\n",
    "            logging.info(\"{}/{} {}\".format(\n",
    "                sub_model.name, layer.name, 'bn' if batch_norm else 'bias'))\n",
    "\n",
    "            filters = layer.filters\n",
    "            size = layer.kernel_size[0]\n",
    "            in_dim = layer.input_shape[-1]\n",
    "\n",
    "            if batch_norm is None:\n",
    "                conv_bias = np.fromfile(wf, dtype=np.float32, count=filters)\n",
    "            else:\n",
    "                bn_weights = np.fromfile(\n",
    "                    wf, dtype=np.float32, count=4 * filters)\n",
    "                bn_weights = bn_weights.reshape((4, filters))[[1, 0, 2, 3]]\n",
    "\n",
    "            conv_shape = (filters, in_dim, size, size)\n",
    "            conv_weights = np.fromfile(\n",
    "                wf, dtype=np.float32, count=np.product(conv_shape))\n",
    "            conv_weights = conv_weights.reshape(\n",
    "                conv_shape).transpose([2, 3, 1, 0])\n",
    "\n",
    "            if batch_norm is None:\n",
    "                layer.set_weights([conv_weights, conv_bias])\n",
    "            else:\n",
    "                layer.set_weights([conv_weights])\n",
    "                batch_norm.set_weights(bn_weights)\n",
    "\n",
    "    assert len(wf.read()) == 0, 'failed to read all data'\n",
    "    wf.close()\n",
    "    \n",
    "\n",
    "# Visualize output\n",
    "def draw_outputs(img, outputs, class_names,no_rbc = True):\n",
    "    boxes, objectness, classes, nums = outputs # predicted outputs\n",
    "    boxes, objectness, classes, nums = boxes[0], objectness[0], classes[0], nums[0]\n",
    "    wh = np.flip(img.shape[0:2])\n",
    "\n",
    "    for i in range(nums):\n",
    "        if no_rbc:\n",
    "            if classes[i]==0:\n",
    "                continue \n",
    "            \n",
    "        x1y1 = tuple((np.array(boxes[i][0:2]) * wh).astype(np.int32))\n",
    "        x2y2 = tuple((np.array(boxes[i][2:4]) * wh).astype(np.int32))\n",
    "        img = cv2.rectangle(img, x1y1, x2y2, (255, 0, 0), 2)\n",
    "        img = cv2.putText(img, '{} {:.4f}'.format(\n",
    "            class_names[int(classes[i])], objectness[i]),\n",
    "            x1y1, cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 2)\n",
    "        \n",
    "    return img\n",
    "\n",
    "\n",
    "# Freeze all layers in model\n",
    "def freeze_all(model, frozen=True):\n",
    "    model.trainable = not frozen\n",
    "    if isinstance(model, tf.keras.Model):\n",
    "        for l in model.layers:\n",
    "            freeze_all(l, frozen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data loader and transformation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below function parse the created csv file and structured into yolo acceptable format\n",
    "# data : dataframe which was created above\n",
    "# class_dict: dictionary containing classes with index(created above)\n",
    "# size : Input size of each image (here by default is 416)\n",
    "# path : path to images data folder\n",
    "\n",
    "def parse_dataset(data, class_dict, size,image, path, yolo_max_boxes):\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for img in tqdm(image):\n",
    "        x_train = Image.open(path+img)\n",
    "        width,height = x_train.size\n",
    "        x_train = x_train.resize((size, size))\n",
    "        x_train = np.array(x_train)\n",
    "        temp_data = []\n",
    "\n",
    "        for _,row in data[data['img_path']==path+img].iterrows():\n",
    "            xmin = row.min_c / width\n",
    "            xmax = row.max_c / width\n",
    "            ymin = row.min_r / height\n",
    "            ymax = row.max_r / height\n",
    "            cls = class_dict[row.category]\n",
    "            temp_data.append([xmin,ymin,xmax,ymax,cls])\n",
    "        temp_data = temp_data + [[0,0,0,0,0]] * (yolo_max_boxes - len(temp_data))\n",
    "        #return(temp)\n",
    "        Y.append(temp_data)\n",
    "        X.append(x_train)\n",
    "    return(np.array(X),np.stack(np.array(Y)))\n",
    "\n",
    "\n",
    "def transform_images(x, size):\n",
    "    x = tf.image.resize(x,(size,size))\n",
    "    x = x / 255.0\n",
    "    return(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
